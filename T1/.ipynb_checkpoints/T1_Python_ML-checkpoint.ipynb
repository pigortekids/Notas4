{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G4HhD53B2rjV"
   },
   "source": [
    "# Trabalho #1 - Python com NumPy\n",
    "\n",
    "\n",
    "Este trabalho fornece uma breve revisão de Python. Mesmo que você já tenha usado Python, esse trabalho irá ajudar você a se familiarizar com as funções que precisaremos nessa disciplina.\n",
    "\n",
    "**Instruções:**\n",
    "- Você estará usando o Python 3.\n",
    "- Evite usar for-loops e while-loops, a menos que seja explicitamente instruído a fazê-lo.\n",
    "- As suas tarefas nesse trabalho estão sinalizadas nas células pelo comentário \"`# PARA VOCÊ FAZER:`\".\n",
    "- Depois de incluir o seu código, execute a célula modificada para verificar se o resultado está correto.\n",
    "\n",
    "**Após esse trabalho você irá:**\n",
    "- Ser capaz de usar os iPython Notebooks\n",
    "- Ser capaz de usar funções numpy e operações de tensores numpy\n",
    "- Compreender o conceito de \"broadcasting\"\n",
    "- Ser capaz de vetorizar um código\n",
    "\n",
    "(Esse trabalho é um adaptação de Adrew Ng, deeplearnig.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvSiPnKH2rjX"
   },
   "source": [
    "## Coloque os nomes e RAs dos alunos que fizeram esse trabalho\n",
    "\n",
    "Nome e número dos alunos da equipe: 20.83992-8\n",
    "\n",
    "Aluno 1: Igor Amaral Correa\n",
    "\n",
    "Aluno 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGpSrZO32rjY"
   },
   "source": [
    "## Sobre os notebooks iPython ##\n",
    "\n",
    "Os notebooks iPython são ambientes de codificação interativos incorporados em uma página da web. Você estará usando notebooks iPython nesta disciplina. Você só precisa escrever código entre os comentários `### COMEÇE AQUI ###` e `### TERMINE AQUI ###`. Depois de escrever seu código, você pode executar a célula pressionando \"SHIFT\" + \"ENTER\" ou clicando em \"Run Cell\" localizado na barra superior do bloco de notas.\n",
    "\n",
    "Frequentemente, especificaremos \"`(≈ X linhas de código)`\" nos comentários para informar sobre quanto código você precisa escrever. Isso é apenas uma estimativa aproximada, por isso não se sinta mal se o seu código for mais longo ou mais curto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usY7YE6y2rjY"
   },
   "source": [
    "### Exercício #1:\n",
    "\n",
    "Modifique a variável teste para `\" Alô Mundo \"` na célula abaixo para imprimir `Alô Mundo` e execute as duas células abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpGEtmy-2rjZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste: Alô Mundo\n"
     ]
    }
   ],
   "source": [
    "# PARA VOCÊ FAZER:\n",
    "\n",
    "### COMEÇE AQUI ### (≈ 1 linha de código)\n",
    "print(\"teste: Alô Mundo\")\n",
    "### TERMINE AQUI ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "542GdDcd2rjc"
   },
   "outputs": [],
   "source": [
    "print (\"teste: \" + teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRusFMDf2rje"
   },
   "source": [
    "**Saída esperada**:\n",
    "\n",
    "    teste: Alô Mundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vv3QeL932rje"
   },
   "source": [
    "**O que você precisa lembrar**:\n",
    "- Executar suas células usando SHIFT + ENTER (ou clicar em \"RUN\" na barra superior)\n",
    "- Escrever código nas áreas designadas usando apenas Python 3\n",
    "- Não modifique o código fora das áreas designadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oWDMYIqq2rjf"
   },
   "source": [
    "## 1 - Construindo funções básicas com numpy ##\n",
    "\n",
    "Numpy é a principal biblioteca de funções para computação científica em Python. É mantido por uma grande comunidade (www.numpy.org). Neste exercício, você aprenderá várias funções de numpy, tais como, np.exp, np.log e np.reshape. Você precisará saber como usar essas funções para futuros trabalhos.\n",
    "\n",
    "### 1.1 - Função sigmoide ###\n",
    "\n",
    "A função sigmoide é baseada na função exponencial. Mas antes de usar a função exponencial da biblioteca numpy, `np.exp()`, você usará a função exponencial da bilbioteca, math `math.exp()`, para implementar a função sigmoide. Você verá então porque `np.exp()` é preferível a `math.exp()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vk8OKoMX2rjf"
   },
   "source": [
    "### Exercício #2:\n",
    "\n",
    "Construa uma função que retorne a sigmoide de um número real `x`. Use `math.exp(x)` para a calcular a função exponencial.\n",
    "\n",
    "**Observação**: a função $  sigmoid(x) = \\frac{1} {1 + e ^ {- x}}  $ é também conhecida como função logística, sendo uma função não linear usada não só em redes neurais mas também em Machine Learning (Regressão Logística).\n",
    "\n",
    "Para se referir a uma função pertencente a um pacote específico, você pode chamá-la usando `package_name.function()`.\n",
    "\n",
    "Modifique e execute o código abaixo para criar e ver a função `basic_sigmoid()` com `math.exp()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5Er-tMU2rjg"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: basic_sigmoid\n",
    "\n",
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calcula sigmoid de x.\n",
    "\n",
    "    Argumentos:\n",
    "    x -- A escalar\n",
    "\n",
    "    Retorna:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMEÇE AQUI ### (≈ 1 linha de código)\n",
    "    s = 1 / ( 1 + math.exp(-x) )\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8RMud7t2rji"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_sigmoid(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnJSkvDT2rjk"
   },
   "source": [
    "**Resultado esperado**: \n",
    "\n",
    "    0.9525741268224334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qR9bO9K72rjk"
   },
   "source": [
    "Na verdade, raramente usamos a biblioteca \"matemática\" em redes neurais porque as entradas das funções são números reais. Em redes neurais usamos principalmente matrizes e vetores (tensores). É por isso que numpy é mais útil. Execute a célula abaxo e veja o que acontece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QFg0ItN2rjl"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f8d61ca34618>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Uma razão para usar \"numpy\" no lugar de \"math\" em redes neurais ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbasic_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# você verá que essa função gera um erro, isso é causado porque x é um vetor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-0a9560fac918>\u001b[0m in \u001b[0;36mbasic_sigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m### COMEÇE AQUI ### (≈ 1 linha de código)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m### TERMINE AQUI ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
     ]
    }
   ],
   "source": [
    "### Uma razão para usar \"numpy\" no lugar de \"math\" em redes neurais ###\n",
    "x = [1, 2, 3]\n",
    "basic_sigmoid(x) # você verá que essa função gera um erro, isso é causado porque x é um vetor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ln3RqYI2rjn"
   },
   "source": [
    "De fato, se $ x = (x_1, x_2, ..., x_n)$ é um vetor linha, então $np.exp(x)$ aplica a função exponencial idependentemente a cada elemento do vetor $x$. A saída será então: $np.exp(x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwpZatRU2rjo",
    "outputId": "975ec939-1bb3-4e4d-d7ac-a484fb602e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # com isso você pode acessar as funções do numpy escrevendo somente np.function() no lugar de numpy.function()\n",
    "\n",
    "# Exemplo de np.exp\n",
    "x = np.array([1, 2, 3])\n",
    "print(np.exp(x)) # resultado é (exp(1), exp(2), exp(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvdUlLjk2rjr"
   },
   "source": [
    "### Exercício #3:\n",
    "\n",
    "Crie alguns tensores numpy e execute algumas operações com esses tensores usando as funções da biblioteca numpay.\n",
    "\n",
    "Se $x$ é um vetor **numpy**, então uma operação em Python, tal como, $s = x + 3$ or $s = \\frac{1}{x}$ irá produzir um vetor de saída $s$ do mesmo tamanho do vetor de entrada $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qd9iQ_0A2rjr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v + 3 =  [4 5 6]\n",
      "1/v =  [1.         0.5        0.33333333]\n",
      "umax =  -1\n",
      "vmin =  1\n",
      "uv =  -14\n",
      "uvi =  [-1 -4 -9]\n"
     ]
    }
   ],
   "source": [
    "# PARA VOCÊ FAZER: operações com vetores\n",
    "\"\"\"\n",
    "    Dados dois vetores u e v  calcule:\n",
    "    s1 = v + 3\n",
    "    s2 = 1/v\n",
    "    umax = valor maximo de u\n",
    "    vmin = valor mínimo de v\n",
    "    uv = produto escalar de u por v\n",
    "    uvi = produto elemento por elemento de v por u\n",
    "\"\"\"\n",
    "\n",
    "v = np.array([1, 2, 3])\n",
    "u = np.array([-1, -2, -3])\n",
    "\n",
    "### COMEÇE AQUI ### (≈ 6 linhas)\n",
    "s1 = v + 3\n",
    "s2 = 1 / v\n",
    "umax = max(u)\n",
    "vmin = min(v)\n",
    "uv = np.dot(u, v)\n",
    "uvi = u * v\n",
    "### TERMINE AQUI ###\n",
    "\n",
    "print(\"v + 3 = \", s1)\n",
    "print(\"1/v = \", s2)\n",
    "print(\"umax = \", umax)\n",
    "print(\"vmin = \", vmin)\n",
    "print(\"uv = \", uv)\n",
    "print(\"uvi = \", uvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQtP7ibR2rjv"
   },
   "source": [
    "**Resultado esperado:**\n",
    "\n",
    "    v + 3 = [4 5 6]\n",
    "    1/v = [1. 0.5 0.33333333]\n",
    "    umax = -1\n",
    "    vmin = 1\n",
    "    uv = -14\n",
    "    uvi = [-1 -4 -9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "davltoYu2rjw"
   },
   "source": [
    "A qualquer momento que você precisar de mais informação sobre uma função do numpy, olhe na [documentação oficial](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html). \n",
    "\n",
    "Você pode também criar uma nova célula no notebook jupiter e escrever `np.exp?` (por exemplo) para conseguir acesso rápido à documentação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMI3FCkY2rjx"
   },
   "source": [
    "### Exercício #4: \n",
    "\n",
    "Implemente a função `sigmoid()` usando numpy. \n",
    "\n",
    "**Instruções**: $x$ pode ser um número real, um vetor, ou uma matriz. A estrutura de dados que se usa em numpy para representar esses tipos de dados (vetores, matrizes, tensores...) são chamados de \"numpy arrays\". \n",
    "\n",
    "$$ \\text{Para } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80-Pu5G02rjy"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: sigmoid\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calcule a fnção sigmoid de x\n",
    "\n",
    "    Argumentos:\n",
    "    x -- Um escalar ou um numpy array de qualquer dimensão\n",
    "\n",
    "    Retorna:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMECE AQUI ### (≈ 1 linha)\n",
    "    s = 1 / ( 1 + np.exp(-x) )\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZCGQtxR2rj0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdWC4ho12rj2"
   },
   "source": [
    "**Saída esperada**: \n",
    "\n",
    "    array([ 0.73105858,  0.88079708,  0.95257413])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TV_PTTwQ2rj2"
   },
   "source": [
    "### 1.2 - Derivada da função sigmoide\n",
    "\n",
    "Como visto em aula, você precisa calcular derivadas para otimizar a função de custo usando a retro-propagação. Vamos codificar a derivada da função sigmoide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4OPIZzNQ2rj3"
   },
   "source": [
    "### Exercício #5:\n",
    "\n",
    "Implemente a função `sigmoid_grad()` para calcular a derivada da função sigmóide em relação à sua entrada x. \n",
    "\n",
    "A fórmula é: $$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))$$\n",
    "\n",
    "Você pode codificar essa função em duas etapas:\n",
    "1. Defina s como sendo a sigmoide de $x$. Use a sua função sigmoide.\n",
    "2. Calcule $\\sigma'(x) = s(1-s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2V2T7_yx2rj3"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: sigmoid_derivative\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Calcule a derivada da função sigmoide em relação à sua entrada. \n",
    "    \n",
    "    Arguments:\n",
    "    x -- um escalar ou um tensor numpy\n",
    "\n",
    "    Return:\n",
    "    ds -- derivada da sigmoide\n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMECE AQUI ### (≈ 2 linhas)\n",
    "    s = sigmoid(x)\n",
    "    ds = s * ( 1 - s )\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oO_xLe6s2rj5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_derivative(x) = [0.19661193 0.10499359 0.04517666]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "print (\"sigmoid_derivative(x) = \" + str(sigmoid_derivative(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hji_znC92rj7"
   },
   "source": [
    "**Saída esperada**: \n",
    "\n",
    "    sigmoid_derivative(x) = [0.19661193 0.10499359 0.04517666]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SRQcF152rj7"
   },
   "source": [
    "### 1.3 - Alterando dimensões de tensores ###\n",
    "\n",
    "Duas funções comuns usadas em deep-learning são [np.shape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) e [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html). \n",
    "- `X.shape(X)` é usada para obter a dimensão de um tensor `X`. \n",
    "- `X.reshape(X)` é usada para alterar a dimensão de `X`. \n",
    "\n",
    "Por exemplo, uma imagem digital é representada por um tensor 3D de dimensões $(length, height, depth = 3)$. Contudo, quando se usa uma imagem como entrada de uma RNA ela em geral deve ser convertida para uma vetor de dimensão $(length*height*3, 1)$. Em outras palavras, deve-se desenrolar ou alterar a dimensão do tensor 3D para um vetor 1D.\n",
    "\n",
    "<img src=\"image2vector_kiank.png\" style=\"width:500px;height:300;\">\n",
    "(Andrew Ng, deeplearning.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhAlO_iD2rj8"
   },
   "source": [
    "### Exercício #6: \n",
    "\n",
    "Implemente uma função `image2vector()` que recebe como entrada uma imagem (tensor) de dimensão (length, height, 3) e retorna um vetor de dimensão (length\\*height\\*3, 1). Por exemplo, se quiser redimensionar um tensor v de dimensão (a, b, c) para um vetor \n",
    "de dimensão (a*b,c) deve-se fazer:\n",
    "\n",
    "``` python\n",
    "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n",
    "```\n",
    "\n",
    "**Observação:** nunca codifique as dimensões de uma imagem como uma constante. No lugar obtenha as dimensões da imagem com a função `image.shape[0]`, ou `image.shape[1]`, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rhs53fS_2rj8"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: image2vector\n",
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argumento:\n",
    "    image -- um tensor numpy de dimensão (length, height, depth)\n",
    "    \n",
    "    Retorna:\n",
    "    v -- um vetor de dimensão (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMECE AQUI ### (≈ 1 linha)\n",
    "    v = image.reshape(( image.shape[0] * image.shape[1] * image.shape[2] , 1 ))\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YH2YY0u_2rj-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2vector(image) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.90714982]\n",
      " [0.52835647]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.85304703]\n",
      " [0.52351845]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.10820313]\n",
      " [0.49978937]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de tensor 3 por 3 by por 2, typicamente uma imagem tem dimensão (num_px_x, num_px_y,3) onde o terceiro eixo representa \n",
    "# os planos de cor RGB\n",
    "image = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print (\"image2vector(image) = \" + str(image2vector(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZWaWPBCs2rkB"
   },
   "source": [
    "**Saída esperada:** \n",
    "\n",
    "    image2vector(image) = [[ 0.67826139]\n",
    "     [ 0.29380381]\n",
    "     [ 0.90714982]\n",
    "     [ 0.52835647]\n",
    "     [ 0.4215251 ]\n",
    "     [ 0.45017551]\n",
    "     [ 0.92814219]\n",
    "     [ 0.96677647]\n",
    "     [ 0.85304703]\n",
    "     [ 0.52351845]\n",
    "     [ 0.19981397]\n",
    "     [ 0.27417313]\n",
    "     [ 0.60659855]\n",
    "     [ 0.00533165]\n",
    "     [ 0.10820313]\n",
    "     [ 0.49978937]\n",
    "     [ 0.34144279]\n",
    "     [ 0.94630077]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkViiitl2rkB"
   },
   "source": [
    "### 1.4 - Normalização de vetores\n",
    "\n",
    "Uma operação comum em Aprendizado de Máquina é normalizar os dados. Em geral a normalização dos dados gera um desemepnho melhor da RNA em razão do gradiente descendente convergir mais rápido com dados normalizados. Nessa tarefa, vamos normalizar um vetor linha dividindo-o pela sua norma 2, ou seja:\n",
    "\n",
    "$$ \\frac{x}{\\| x\\|} $$\n",
    "\n",
    "Por exemplo, se: \n",
    "\n",
    "$$x = \\begin{bmatrix}\n",
    "    0 & 3 & 4 \\\\\n",
    "    2 & 6 & 4 \\\\\n",
    "\\end{bmatrix}$$ \n",
    "\n",
    "então essa operação pode ser realizada pela seguinte função Numpy: \n",
    "\n",
    "$$\\| x\\| = np.linalg.norm(x, axis = 1, keepdims = True) = \\begin{bmatrix}\n",
    "    5 \\\\\n",
    "    \\sqrt{56} \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "e por: \n",
    "\n",
    "$$ x\\_normalized = \\frac{x}{\\| x\\|} = \\begin{bmatrix}\n",
    "    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n",
    "    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n",
    "\\end{bmatrix}$$ \n",
    "\n",
    "Note que é possível dividir matrizes de dimensões diferentes sem problemas, pois o \"broadcasting\" faz isso automaticamente.\n",
    "\n",
    "**Observação:** Verifique na documentação da biblioteca numpy o que significa os argumentos `axis` e `keepdims` na função `linalg.norm`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3M8eJOa2rkC"
   },
   "source": [
    "### Exercício #7: \n",
    "\n",
    "Implemente a função `normalizeRows()` para normalizar as linhas de uma matriz. Após aplicar essa função em uma matriz cada linha deve ser um vetor com norma 2 igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61QP80DW2rkD"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: normalizeRows\n",
    "\n",
    "def normalizeRows(x):\n",
    "    \"\"\"\n",
    "    Implemente uma função que normaliza cada linha de uma matriz de forma que tenham norma unitária.\n",
    "    \n",
    "    Argumento:\n",
    "    x -- Uma matriz numpy de dimensões (n, m)\n",
    "    \n",
    "    Retorna:\n",
    "    x -- A matriz normalizada (linha por linha).\n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMECE AQUI ### (≈ 2 linHAS)\n",
    "    # Calcule x_norm como sendo a norma 2 de x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "    x_norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)\n",
    "    x = x / x_norm\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW17813-2rkG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz normalizada = [[0.         0.6        0.8       ]\n",
      " [0.13736056 0.82416338 0.54944226]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [0, 3, 4],\n",
    "    [1, 6, 4]])\n",
    "print(\"Matriz normalizada = \" + str(normalizeRows(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efnfarxB2rkJ"
   },
   "source": [
    "**Saída esperada:** \n",
    "\n",
    "    Matriz normalizada = [[ 0.          0.6         0.8       ]\n",
    "     [ 0.13736056  0.82416338  0.54944226]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3_G6CcE2rkJ"
   },
   "source": [
    "**Observação:**\n",
    "\n",
    "Tente na função `normalizeRows()` imprimir as dimensões de `x_norm` e `x` e executar novamente. Você verá que eles tem dimensões diferentes. Isso é óbvio dado que `x_norm` é um único valor para cada linha de `x`. Portanto a dimensão de `x_norm` é igual ao número de linhas de `x`, mas é somente um vetor coluna. A divisão de `x` por `x_norm` só é possível pelo \"broadcast\" (ajuste) feito automaticamente pelo Numpy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgzkQHJ52rkK"
   },
   "source": [
    "### 1.5 - Broadcasting e a função softmax ####\n",
    "Como vimos na teoria um conceito muito importante em Numpy é o ajuste automático de dimensões (\"broadcasting\"). O \"broadcasting\" é muito útil para realizar operações matemáticas entre tensores de dimensões diferentes. Para ver todos os detalhes do conceito de \"broadcasting\", você pode ver a documentação oficial do broadcasting  [broadcasting documentation](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcHinqqC2rkL"
   },
   "source": [
    "### Exercício #8: \n",
    "\n",
    "Implemente uma função chamada `softmax` usando numpy. Você pode considerar que a função `softmax` é uma função que normaliza as linhas da exponencial de cada elemento de uma matriz.\n",
    "\n",
    "**Instrucões:**\n",
    "- $ \\text{para um vetor } x \\in \\mathbb{R}^{1\\times n} \\text{,     } softmax(x) = softmax(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix}$ \n",
    "\n",
    "- $\\text{para uma matrix } x \\in \\mathbb{R}^{m \\times n} \\text{: }$  $$softmax(x) = softmax\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} = \\begin{pmatrix}\n",
    "    softmax\\text{(primeira linha de x)}  \\\\\n",
    "    softmax\\text{(segunda linha de x)} \\\\\n",
    "    ...  \\\\\n",
    "    softmax\\text{(última linha de x)} \\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "- $\\text{para calcular a somatoria dos elementos de um vetor pode ser usada a função np.sum() da seguinte forma:}$ $\\| x\\| = np.sum(x, axis = 1, keepdims = True)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_3gaFv2Z2rkL"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: softmax\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Calcule a função softmax para cada linha da matriz de entrada x.\n",
    "\n",
    "    Seu programa deve funcionar para um vetor linha e também para matrizes de dimensões genéricas (n, m).\n",
    "\n",
    "    Argumento:\n",
    "    x -- Uma matriz numpy de dimensões (n,m)\n",
    "\n",
    "    Retorna:\n",
    "    s -- Uma matriz numpay de dimensões A numpy matrix equal to the softmax of x, of shape (n,m)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMECE AQUI ### (≈ 3 lINHAS)\n",
    "    x_exp = np.exp(x)\n",
    "    x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    s = x_exp / x_sum\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QOgP85J2rkO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qrKjYGk92rkR"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    softmax(x) = [[  9.80897665e-01   8.94462891e-04   1.79657674e-02   1.21052389e-04\n",
    "      1.21052389e-04]\n",
    "     [8.78679856e-01   1.18916387e-01   8.01252314e-04   8.01252314e-04\n",
    "      8.01252314e-04]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2KgJzrt2rkS"
   },
   "source": [
    "**Nota**: Se você imprimir as dimensões de `x_exp`, `x_sum` e `s` acima, você verá que `x_sum` tem dimensão (2,1) enquanto que `x_exp` e `s` tem dimensões (2,5). O cálculo **x_exp/x_sum** funciona em razão do \"broadcasting\" em Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2FCmRSY2rkS"
   },
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**O que é preciso lembrar:**\n",
    "\n",
    "- `np.exp(x)` funciona para qualquer tensor numpy e aplica a função exponencial em todos os elementos do tensor;\n",
    "- a função `sigmoide`, sua derivada e a função `image2vector` são muito usadas em deep-learning;\n",
    "- `np.reshape` é amplamente utilizada; \n",
    "- manter as dimensões dos tensores corretas é muito importante;\n",
    "- numpy possui muitas funcções úteis;\n",
    "- broadcasting é extremamente útil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkE-DdKQ2rkT"
   },
   "source": [
    "## 2 - Vectorização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2jo9P4R2rkU"
   },
   "source": [
    "Como visto na teoria, em deep-learning lidamos com conjunto de dados extremamente grandes. Portanto, as funções devem ser otimizadas para não criar um gargalo computacional e demorar muito para realizar os cálculos. Para tornar um programa eficiente devemos usar vetorização dos cálculos. Por exemplo, vamos ver a diferencça entre as seguintes implementações das funções produto escalar (produto interno), produto externo e produto de elemento por elemento de dois vetores implementadas classicamente com loops e de forma vetorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnFtI3Q42rkV",
    "outputId": "e48c43d4-a88e-434a-f95d-dc43a4cf6291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produto escalar = 278\n",
      "produto de dois vetores = [[81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [63. 14. 14. 63.  0. 63. 14. 35.  0.  0. 63. 14. 35.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [81. 18. 18. 81.  0. 81. 18. 45.  0.  0. 81. 18. 45.  0.  0.]\n",
      " [18.  4.  4. 18.  0. 18.  4. 10.  0.  0. 18.  4. 10.  0.  0.]\n",
      " [45. 10. 10. 45.  0. 45. 10. 25.  0.  0. 45. 10. 25.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "multiplicação elemento-por-elemento = [81.  4. 10.  0.  0. 63. 10.  0.  0.  0. 81.  4. 25.  0.  0.]\n",
      "produto matriz-vetor = [19.15825122 22.35571409 24.49820791]\n",
      " ----- Tempo de computação = 15.625ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO ESCALAR ENTRE DOIS VETORES ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot+= x1[i]*x2[i]\n",
    "print (\"produto escalar = \" + str(dot))\n",
    "\n",
    "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO EXTERNO ENTRE DOIS VETORES ###\n",
    "outer = np.zeros((len(x1),len(x2))) # primeiramente criamos uma matriz de zeros com dimensão len(x1) x len(x2)\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i]*x2[j]\n",
    "#toc = time.process_time()\n",
    "print (\"produto de dois vetores = \" + str(outer))\n",
    "\n",
    "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO DE DOIS VETORES ELEMENTO POR ELEMENTO ###\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i]*x2[i]\n",
    "#toc = time.process_time()\n",
    "print (\"multiplicação elemento-por-elemento = \" + str(mul))\n",
    "\n",
    "### IMPLEMENTAÇÃO CLÁSSICA DO PRODUTO DE UMA MATRIZ POR UM VETOR ###\n",
    "np.random.seed(3)\n",
    "W = np.random.rand(3,len(x1)) # Vetor numpy com números aletórios de dimensão 3 x len(x1)\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"produto matriz-vetor = \" + str(gdot) + \"\\n ----- Tempo de computação = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApKwG1Jg2rkW"
   },
   "source": [
    "### Exercício #9: \n",
    "\n",
    "Implemente os cálculos da célula anterior mas de forma vetorizada. Para fazer isso você pode usar as seguintes funções da biblioteca numpy: `dot`, `outer`, `multiply` e o operador `*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7kLk-5W2rkX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produto escalar = 278\n",
      "produto de dois vetores = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "produto elemento-por-elemento = [81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
      " produto matriz-vetor = [19.15825122 22.35571409 24.49820791]\n",
      " ----- Computation time = 0.0ms\n"
     ]
    }
   ],
   "source": [
    "# PARA VOCÊ FAZER: vetorização\n",
    "\n",
    "x1 = np.array([9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0])\n",
    "x2 = np.array([9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0])\n",
    "\n",
    "tic = time.process_time()\n",
    "\n",
    "### PRODUTO ESCALAR VEOTRIZADO (x1 por x2) ###\n",
    "### COMECE AQUI ### (≈ 1 lINHA)\n",
    "dotv1 = np.dot( x1 , x2 )\n",
    "### TERMINE AQUI ###\n",
    "print (\"produto escalar = \" + str(dotv1))\n",
    "\n",
    "### PRODUTO MATRICIAL DE DOIS VETORES VECTORIZADO (x1 por x2) ###\n",
    "### COMECE AQUI ### (≈ 1 lINHA)\n",
    "outerv = np.outer( x1 , x2 )\n",
    "### TERMINE AQUI ###\n",
    "print (\"produto de dois vetores = \" + str(outerv))\n",
    "\n",
    "### PRODUTO DE DOIS VETORES ELEMENTO-POR-ELEMENTO VECTORIZADO (x1 por x2) ###\n",
    "### COMECE AQUI ### (≈ 1 lINHA)\n",
    "mulv = np.multiply( x1 , x2 )\n",
    "### TERMINE AQUI ###\n",
    "print (\"produto elemento-por-elemento = \" + str(mulv))\n",
    "\n",
    "### PRODUTO MATRIX-VETOR VETORIZADO (W por x1) ###\n",
    "### COMECE AQUI ### (≈ 1 lINHA)\n",
    "dotv2 = np.dot( W , x1 )\n",
    "### TERMINE AQUI ###\n",
    "\n",
    "toc = time.process_time()\n",
    "print (\" produto matriz-vetor = \" + str(dotv2) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkK83vPU2rkZ"
   },
   "source": [
    "**Saída esperada**:\n",
    "\n",
    "    produto escalar = 278\n",
    "    produto de dois vetores = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
    "     [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
    "     [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
    "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
    "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
    "     [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
    "     [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
    "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
    "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
    "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
    "     [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
    "     [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
    "     [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
    "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
    "     [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
    "    produto elemento-por-elemento = [81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
    "     produto matriz-vetor = [19.15825122 22.35571409 24.49820791]\n",
    "     ----- Computation time = 0.0ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ragF3LP42rkZ"
   },
   "source": [
    "Como se pode ver, a implementação vetorizada é muito mais simples e mais eficiente. Para tensores vetores/matrizes maiores a diferença de tempo computacional é ainda maior. \n",
    "\n",
    "**Note** que a função `np.dot()` realiza uma multiplicação entre matriz-matriz ou matriz-vetor, ou ainda entre quaisquer tensores desde que as dimensões sejam compatíveis. A função `np.multiply()` e o operador `*` realizam multiplicação elemento-por-elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zoXZLM_D2rkc"
   },
   "source": [
    "### 2.1 - Implementação de funções de erro, ou de perda\n",
    "\n",
    "Como visto em aula, funções de erro (ou de perda) são utilizadas em deep-learning para calcular o erro entre a saída esperada e a saída calculada pela rede. \n",
    "\n",
    "Essas funções são usadas para avaliar a RNA. Quanto maior o erro, pior são as previsões ($ \\hat{y} $) em relação aos valores reais ($y$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uePziHNr2rke"
   },
   "source": [
    "### Exercício #10:\n",
    "\n",
    "Implemente uma versão vetorizada da função de erro absoluto:\n",
    "\n",
    "$$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=1}^m|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}$$\n",
    "\n",
    "Utilize as funções numpy `np.sum(x)` (soma de todos os elementos do vetor $x$) e `np.abs(x)` (valor absoluto dos elementos do vetor $x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fm9UKejQ2rkf"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: L1\n",
    "\n",
    "def L1(yhat, y):\n",
    "    \"\"\"\n",
    "    ArgumentOs:\n",
    "    yhat -- vetor de dimensão m (valores previstos)\n",
    "    y -- vetor de dimensão m (valores reais)\n",
    "    \n",
    "    Retorna:\n",
    "    loss -- valor da função de erro L1 \n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMEÇE AQUI ### (≈ 1 linha)\n",
    "    loss = np.sum( np.abs( y - yhat ) )\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rHAx9QT2rkh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnove8Xg2rki"
   },
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    L1 = 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nzYmvEi2rkj"
   },
   "source": [
    "### Exercício #11:\n",
    "\n",
    "Implemente uma versão vetorizada da função de erro quadrático:\n",
    "\n",
    "$$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^m(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}$$\n",
    "\n",
    "**Observação:** Existem diversas formas de implementar essa função, mas talvez a forma mais fácil é usando a função numpy `np.dot`. Relembrando que, se $x = [x_1, x_2, ..., x_n]$, então `np.dot(x,x)` = $\\sum_{j=1}^n x_j^{2}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8Su0lma2rkj"
   },
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: FUNÇÃO L2\n",
    "\n",
    "def L2(yhat, y):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    yhat -- vetor de dimensão mx1 (valores previstos)\n",
    "    y -- vetor de dimensão mx1 (valores reais)\n",
    "    \n",
    "    Retorna:\n",
    "    loss -- o valor da função de erro L2\n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMEÇE AQUI ### (≈ 1 linha)\n",
    "    loss = np.sum( np.dot( y - yhat , y - yhat ) )\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZSRPEw82rkl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L2 = \" + str(L2(yhat,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ef9xyNE_2rkm"
   },
   "source": [
    "**Saída esperada:** \n",
    "\n",
    "    L2 = 0.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Neurônio\n",
    "\n",
    "Na Figura abaixo é apresentado um neurônio com 3 entradas. \n",
    "\n",
    "<img src=\"neuronio.png\" style=\"width:300px;height:200;\">\n",
    "\n",
    "As equações que descrevem o funcionamento de um neurônio foram vistas em aula e são as seguintes:\n",
    "\n",
    "  $$z = \\mathbf{Wx} + b$$\n",
    "\n",
    "  $$a = g(z)$$\n",
    "\n",
    "onde:\n",
    "- $z$ = estado do neurônio \n",
    "- $\\mathbf{W}$ = matriz de pesos das ligações dos neurônios de dimensão (1, nx)\n",
    "- $\\mathbf{x}$ = vetor de entradas do neurônio de dimensão (nx, 1)\n",
    "- $b$ = viés do neurônio\n",
    "- $a$ = ativação do neurônio\n",
    "- $g()$ = função de ativação do neurônio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #12:\n",
    "\n",
    "Na célula abaixo defina uma função que implementa uma versão vetorizada para um único exemplo do funcionamento de um neurônio. Utilize a função `sigmoid(x)` feita no exercício #5. Observe que nessa função os parâmetros do neurônio ($\\mathbf{W}$ e $b$) são passados em um dicionário. Passar parâmetros para funções em dicionários simplifica o código quando temos muitos parâmetros, tal como é o caso de uma RNA de várias camadas.\n",
    "\n",
    "Para criar um dicionário de parametros usa-se, por exemplo, `parameters = {'W': w, 'b': b}`. Para recuperar os parâmetros do dicionário parameters você deve usar `parameters[\"..\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: FUNÇÃO neuronio\n",
    "\n",
    "def neuronio(x, parameters):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    x = vetor de entradas de dimensão (1, nx)\n",
    "    parameters = dicionário com parâmetros do neurônio contendo o vetor de pesos W de dimensão (1, nx) e o viés b\n",
    "    \n",
    "    Retorna:\n",
    "    a = ativação do neurônio\n",
    "    \"\"\"\n",
    "    \n",
    "    ### COMEÇE AQUI ### (≈ 2 linhas)\n",
    "    # Recupere o vetor de pesos W e o viés b do dicionário par\n",
    "    w = parameters['W']\n",
    "    b = parameters['b']\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    ### COMEÇE AQUI ### (≈ 2 linhas)\n",
    "    # Calcula a saída do neurônio tendo a sua entrada (x) e os seus parâmetros (W e b)\n",
    "    z = np.dot( w , x ) + b\n",
    "    a = sigmoid( z )\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ativação do neurônio= [[0.92368354]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "x = np.random.random((5,1))\n",
    "w = np.random.random((1,5))\n",
    "b = np.random.random((1))\n",
    "parameters = {'W': w, 'b': b}\n",
    "\n",
    "a = neuronio(x,parameters)\n",
    "print('Ativação do neurônio=', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "    \n",
    "    Ativação do neurônio= [[0.92368354]]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PUHJIk8l2rkn"
   },
   "source": [
    "<font color='blue'>\n",
    "\n",
    "**O que deve ser lembrado:**\n",
    "\n",
    "- Vectorização é muito importante em deep-learning. Ela fornece eficiência computacional, simplicidade e clareza;\n",
    "- Algumas funções de erro bastante utilizadas;\n",
    "- Familiarização com muitas funções numpy, tais como, np.dot, np.sum, np.multiply, np.maximum etc;\n",
    "- Uso de dicionários facilita passar arqumentos para funções."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "T1_Python_ML.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XHpfv",
   "launcher_item_id": "Zh0CU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
