{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho #5 - Regularização\n",
    "\n",
    "Redes neurais deep learning tem tanta flexibilidade e capacidade que o problema de **\"overfitting\"** se torna muito sério se o conjunto de dados de treinamento não for grande o suficiente. A RNA pode fornecer ótimos resultados para os dados de treinameno, mas não é capaz de **generalizar para novos exemplos nunca vistos**.\n",
    "\n",
    "**Nesse trabalho você irá usar métodos de regularização para melhorar o desempenho de sua RNA.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coloque os nomes e RAs dos alunos que fizeram esse trabalho\n",
    "\n",
    "Nome e número dos alunos da equipe:\n",
    "\n",
    "Aluno 1:\n",
    "\n",
    "Aluno 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Bibliotecas\n",
    "\n",
    "Em primeiro lugar é necessário importar algumas bibliotecas do Python que serão usados nesse trabalho:\n",
    "- [numpy](www.numpy.org) pacote de cálculo científico com Python\n",
    "- [sklearn](http://scikit-learn.org/stable/) fornece ferramentes eficientes e simples para análise de dados \n",
    "- [matplotlib](http://matplotlib.org) biblioteca para gerar gráficos em Python\n",
    "- scipy.io fornece funções de entrada e saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import scipy.io\n",
    "from utils import plot_decision_boundary, load_2D_dataset\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2 - Definição do problema ##\n",
    "\n",
    "Um time de football quer desenvolver um sistema de IA para recomendar posições onde o goleiro deve chutar a bola para que os jogadores do time possam pegá-la mais facilmente e, assim, iniciar jogadas mais eficientes.\n",
    "\n",
    "<img src=\"field_kiank.png\" style=\"width:600px;height:350px;\">\n",
    "<caption><center> <u> **Figure 1** </u>: **Campo de football**<br> O goleiro chuta a bola para frente e os jogadores dos dois times tentam pegá-la (Andrew Ng, deeplearning.ai)</center></caption>\n",
    "\n",
    "O time fornece o seguinte conjunto de dados, que corresponde às posições onde o goleiro chutou a bola e com qual time ficou a posse da mesma nos últimos 10 jogos.\n",
    "\n",
    "Esse problema foi criado por Adrew Ng (deeplearning.ai).\n",
    "\n",
    "Execute a célula abaixo para carregar os dados do problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = load_2D_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na figura acima, cada círculo correponde a uma posição do campo de futeball onde um jogador pegou a bola após o goleiro chutar a mesma a partir do gol do lado esquerdo do campo.\n",
    "\n",
    "- Círculo azul representa os jogadores do time do goleiro que ficaram com a posse da bola após o chute do goleiro;\n",
    "- Círculo vermelho representa os jogadores do time adversário que ficaram com a posse da bola após o chute do goleiro.\n",
    "\n",
    "### Objetivo do trabalho\n",
    "\n",
    "- Desenvolver uma RNA dep learning para determinar as posições no campo de futebol onde o goleiro do time deve chutar a bola para que um jogador do time fique com a posse da mesma.\n",
    "- Observe que esse problema é um problema de classificação binária onde se deseja determinar a probabilidade do time do goleiro ficar com a bola se ela cair em uma dada posição do campo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Análise dos dados ##\n",
    "\n",
    "Esse conjunto de dados apresenta um pouco de ruído, mas parece que uma reta diagonal, vindo de cima para baixo da direita para esquerda, separando a metade superior com bolinhas predominantemente azul da metade inferior com bolinhas predominantemente vermelhas funcionaria bem. \n",
    "\n",
    "Vamos calcular a dimensão dos dados para verificar se estão de acordo com que o Keras espera do formato dos dados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo das dimensões dos dados de entrada e saída dos conjuntos de treinamento e teste\n",
    "print('Dimensão dos dados de entrada do conjunto de treinamento: ', X_train.shape)\n",
    "print('Dimensão dos dados de saída do conjunto de treinamento: ', Y_train.shape)\n",
    "print('Dimensão dos dados de entrada do conjunto de validação: ', X_val.shape)\n",
    "print('Dimensão dos dados de saída do conjunto de validação: ', Y_val.shape)\n",
    "print('Dimensão dos dados de entrada do conjunto de teste: ', X_test.shape)\n",
    "print('Dimensão dos dados de saída do conjunto de teste: ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se perceber que cada exemplo de treinamento é uma coluna do conjunto de dados. Como o Keras espera que cada exemplo seja uma linha do conjunto de dados, então temos que redimensionar todos os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #1: Redimensionamento dos dados\n",
    "\n",
    "Redimensione os dados de entrada e de saída dos conjuntos de teste e de treinamento de forma que cada exemplo corresponda a uma linha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Redimensionamento dos dados\n",
    "\n",
    "### COMECE AQUI ### (≈ 6 linhas)\n",
    "#X_train \n",
    "#Y_train\n",
    "#X_val\n",
    "#Y_val \n",
    "#X_test \n",
    "#Y_test\n",
    "### TERMINE AQUI ###\n",
    "\n",
    "print('Dimensão dos dados de entrada do conjunto de treinamento: ', X_train.shape)\n",
    "print('Dimensão dos dados de saída do conjunto de treinamento: ', Y_train.shape)\n",
    "print('Dimensão dos dados de entrada do conjunto de validação: ', X_test.shape)\n",
    "print('Dimensão dos dados de saída do conjunto de validação: ', Y_test.shape)\n",
    "print('Dimensão dos dados de entrada do conjunto de teste: ', X_test.shape)\n",
    "print('Dimensão dos dados de saída do conjunto de teste: ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "    \n",
    "    Dimensão dos dados de entrada do conjunto de treinamento:  (211, 2)\n",
    "    Dimensão dos dados de saída do conjunto de treinamento:  (211, 1)\n",
    "    Dimensão dos dados de entrada do conjunto de validação:  (100, 2)\n",
    "    Dimensão dos dados de saída do conjunto de validação:  (100, 1)\n",
    "    Dimensão dos dados de entrada do conjunto de teste:  (100, 2)\n",
    "    Dimensão dos dados de saída do conjunto de teste:  (100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #2: Cálculo de parâmetros estatísiticos dos dados \n",
    "\n",
    "Pela visualização dos dados parece que eles já estão adequados para serem usados por uma RNA, porém precisamos verificar se não é necessária alguma operação de normalização. Na célula abaixo calcule a média e desvio padrão dos dados de treinamento para verificar se é necessário fazer alguma operação adicional nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Cálculo da média e desvio padrão dos dados de treinamento\n",
    "\n",
    "# Calculo das médias e desvios padrão dos dados de entrada do conjunto de treinamento\n",
    "### COMECE AQUI ### (≈ 4 linhas)\n",
    "#meanx \n",
    "#stdx \n",
    "#maxx\n",
    "#minx \n",
    "### TERMINE AQUI ###\n",
    "\n",
    "print('Média dos dados de entrada do conjunto de treinamento: ', meanx)\n",
    "print('Desvio padrão dos dados de saída do conjunto de treinamento: ', stdx)\n",
    "print('Valor máximo dos dados de entrada: ', maxx)\n",
    "print('Valor mínimo dos dados de entrada: ', minx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Média dos dados de entrada do conjunto de treinamento:  [-0.13024551 -0.05974335]\n",
    "    Desvio padrão dos dados de saída do conjunto de treinamento:  [0.20004073 0.31400379]    \n",
    "    Valor máximo dos dados de entrada:  0.573392\n",
    "    Valor mínimo dos dados de entrada:  -0.657895\n",
    "    \n",
    "Como pode-se perceber, os dados não estão normalizados, ou seja, não possuem média zero nem desvio padrão igual a um, mas como estão dentro do ontervalo -1 a +1 não é preciso normalizá-los.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - RNA base\n",
    "\n",
    "Primeiramente você tentará usar uma RNA simples, sem nenhuma forma de regularização, para ajustar os dados. Após isso você vai aprimorar a sua RNA usando regularização para obter bons resultados e resolver o problema do time de football.\n",
    "\n",
    "### Exercício #3: Criação da RNA\n",
    "\n",
    "Para resolver esse problema você vai usar uma RNA com 2 camadas intermediárias e uma camada de saída com as seguintes características:\n",
    "\n",
    "- Primeira camada: número de neurônios n1, função de ativação ReLu;\n",
    "- Segunda camada: número de neurônios n2, função de ativação ReLu;\n",
    "- Camada de saída: número de neurônio n3, função de ativação sigmóide.\n",
    "\n",
    "Como iremos usar essa mesma RNA diversas vezes, na célula abaixo crie uma função que recebe a dimensão dos dados de entrada e os números de neurônios das 3 camadas e configure a RNA de acordo com as características acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Função para criação da RNA base\n",
    "\n",
    "# Importa classes do Keras de modelos e camadas\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(data_shape, n1, n2, n3):\n",
    "    \"\"\"\n",
    "    Essa função configura uma rede neural deep-learnig\n",
    "    \n",
    "    Argumentos:\n",
    "    data_shape = tuple com dimensões dos dados de entrada da rede\n",
    "    n1 = número de neurônios da primeira camada\n",
    "    n2 = número de neurônios da segunda camada\n",
    "    n3 = número de neurônios da camada de saída\n",
    "       \n",
    "    Retorna: modelo da rede neural\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Adicione as camadas em seu modelo de RNA\n",
    "    #### COMECE AQUI ### (≈ 3 linhas)\n",
    "    #\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #4: Configuração da RNA\n",
    "\n",
    "Defina os números de neurônios das camadas intermediárias e de saída e crie a RNA usando a função build_model criada na célula anterior. Utilize n1 = 40, n2 = 6, n3 = 1. Após criar a RNA utilize o método summary para visualizar a sua rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: configuração da RNA base\n",
    "\n",
    "# Inicializa o gerador de números aleatórios\n",
    "np.random.seed(43)\n",
    "\n",
    "# Dimensão dos dados de entrada\n",
    "data_shape = (2,)\n",
    "\n",
    "# Definição dos números de neurônios das camadas\n",
    "#### COMECE AQUI ### (≈ 3 linhas)\n",
    "#n1 \n",
    "#n2 \n",
    "#n3 \n",
    "### TERMINE AQUI ###\n",
    "\n",
    "# Cria rede neural deep learning e apresenta sua configuração\n",
    "#### COMECE AQUI ### (≈ 2 linhas)\n",
    "#rna0 \n",
    "#\n",
    "### TERMINE AQUI ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    dense_1 (Dense)              (None, 40)                120       \n",
    "    _________________________________________________________________\n",
    "    dense_2 (Dense)              (None, 6)                 246       \n",
    "    _________________________________________________________________\n",
    "    dense_3 (Dense)              (None, 1)                 7         \n",
    "    =================================================================\n",
    "    Total params: 373\n",
    "    Trainable params: 373\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #5: Número de parâmetros da RNA\n",
    "\n",
    "Calcule o número de parâmetros da sua RNA. Escreva as contas realizadas e os seus resultados a seguir:\n",
    "\n",
    "- Número de parâmetros da camada 1 = \n",
    "- Número de parâmetros da camada 2 =\n",
    "- Número de parâmetros da camada 3 = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #6: Compilação e treinamento da RNA\n",
    "\n",
    "Agora você vai treinar a sua RNA usando o método de otimização do gradiente descentende com momento. Assim, na célula abaixo, compile e treine a sua RNA usando os seguinte hiperparâmetros:\n",
    "\n",
    "- métrica: exatidão;\n",
    "- método do gradiente descendente com momento;\n",
    "- constante beta1 = 0,9;\n",
    "- decay = 0;\n",
    "- taxa de aprendizagem = 0,01;\n",
    "- nesterov = True\n",
    "- número de épocas = 30.000;\n",
    "- batch_size = 211. \n",
    "\n",
    "**Importante:** Escolha o parâmetro verbose=0 no método fit para evitar de imprimir os resultados das 30.000 épocas de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: compilação e treinamento da RNA base usando o método do gradiente descendente com momento\n",
    "\n",
    "# importa do keras a classe dos otimizadores\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Configuração do otomizador\n",
    "### COMECE AQUI ### (≈ 2 linhas)\n",
    "#mom \n",
    "#\n",
    "### TERMINE AQUI ###\n",
    "\n",
    "# Treinamento da RNA\n",
    "### COMECE AQUI ### (≈ 1 linha)\n",
    "#history \n",
    "### TERMINE AQUI ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos resultados\n",
    "\n",
    "Execute a célula a seguir para fazer os gráficos da função de custo e da métrica para os dados de treinamento e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva treinamento na variável history para visualização\n",
    "history_dict = history.history\n",
    "\n",
    "# Salva custos, métricas e epocas em vetores \n",
    "custo = history_dict['loss']\n",
    "acc = history_dict['acc']\n",
    "val_custo = history_dict['val_loss']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "# Cria vetor de épocas\n",
    "epocas = range(1, len(custo) + 1)\n",
    "\n",
    "# Gráfico dos valores de custo\n",
    "plt.plot(epocas, custo, 'bo', label='Custo - treinamento')\n",
    "plt.plot(epocas, val_custo, 'b', label='Custo - validação')\n",
    "plt.title('Valor da função de custo – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Custo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico dos valores da métrica\n",
    "plt.plot(epocas, acc, 'bo', label='exatidao- treinamento')\n",
    "plt.plot(epocas, val_acc, 'b', label='exatidao - validação')\n",
    "plt.title('Valor da métrica – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exatidao')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula a seguir para calcular o custo e a exatidão pra os dados de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método evaluate calcule o custo e a exatidão e depois apresenta os resultados\n",
    "custo_e_metricas_train = rna0.evaluate(X_train, Y_train)\n",
    "custo_e_metricas_val = rna0.evaluate(X_val, Y_val)\n",
    "custo_e_metricas_test = rna0.evaluate(X_test, Y_test)\n",
    "\n",
    "print(custo_e_metricas_train)\n",
    "print(custo_e_metricas_val)\n",
    "print(custo_e_metricas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    [0.1255700254892286, 0.9526066]\n",
    "    [0.8738724040985107, 0.94]\n",
    "    [0.8637536449357868, 0.94]\n",
    "\n",
    "Execute a célula abaixo para visualizar a fronteira de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"RNA base\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0.75,0.40])\n",
    "axes.set_ylim([-0.75,0.65])\n",
    "plot_decision_boundary(rna0, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos resultados\n",
    "\n",
    "Pelos gráficos da função de custo e da métrica você deve observar o seguinte:\n",
    "\n",
    "- O valor do custo para os dados de treinamento diminui rapidamente no início depois apresenta uma diminuição lenta e estabiliza em um valor de cerca de 0,12.\n",
    "- O valor do custo para os dados de validação diminui até por volta da época 8000 e depois aumenta bruscamente e estabiliza em um valor bem alto, o que representa um resultado muito ruim.\n",
    "- A exatidão obtida para os dados de treinamento é de 95%, para os dados de validação é de 94% e para os dados de teste é de 94%.\n",
    "\n",
    "Por esses resultados e principalmente pelo gráfico da fronteira de decisão pode-se concluir que essa RNA está obviamente realizando \"overfitting\" dos dados de trenamento, pois ela está ajustando os ruídos.\n",
    "\n",
    "Como temos uma RNA que está realizando \"overfitting\", então vamos implementar técnicas de regularização para reduzir e obter uma RNA que apresenta bom desempenho para os dados de teste. Primeiramente vamos tentar a regularização L2 e depois dropout. \n",
    "\n",
    "Essa RNA será utilizada como base para você visualizar o impacto da regularização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Regularização L2\n",
    "\n",
    "### Exercício #7: Criação da RNA com regularização L2\n",
    "\n",
    "A regularização L2 é implementada no Keras durante a criação da RNA. Então crie a função build_model_L2, modificando a sua função build_model para incluir a regularização L2. \n",
    "\n",
    "Utilize novamente a mesma configuração da RNA, ou seja, 2 camadas intermediárias e uma camada de saída com as seguintes características:\n",
    "\n",
    "- Primeira camada: número de neurônios n1, função de ativação ReLu;\n",
    "- Segunda camada: número de neurônios n2, função de ativação ReLu;\n",
    "- Camada de saída: número de neurônios n3, função de ativação sigmóide;\n",
    "- Inclua regularização em todas as camadas.\n",
    "\n",
    "Essa função deve receber como entrada a dimensão dos dados de entrada, os números de neurônios das 3 camadas e o parâmetro de regularização (lamb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Função para criação da RNA com regularização L2\n",
    "\n",
    "# Importa classes do Keras de modelos e camadas\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def build_model_L2(data_shape, n1, n2, n3, lamb):\n",
    "    \"\"\"\n",
    "    Essa função configura uma rede neural deep-learnig\n",
    "    \n",
    "    Argumentos:\n",
    "    data_shape = tuple com dimensões dos dados de entrada da rede\n",
    "    n1 = número de neurônios da primeira camada\n",
    "    n2 = número de neurônios da segunda camada\n",
    "    n3 = número de neurônios da camada de saída\n",
    "    lamb = parâmetro de regularização\n",
    "       \n",
    "    Retorna: modelo da rede neural\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Adicione as camadas em seu modelo de RNA\n",
    "    #### COMECE AQUI ### (≈ 3 linhas)\n",
    "    #\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo configure a sua RNA usando os mesmos parâmetros da RNA base, ou seja, n1 = 40, n2 = 6, n3 = 1. Após criar a RNA utilize o método summary para visualizar a sua rede.\n",
    "\n",
    "**Importante: nesse exercício o seu objetivo é obter uma RNA que não realiza \"overfitting\" usando o método de regularização L2. A escolha do  parâmetro de regularização (lambda na célula abaixo) é fundamental para que a RNA apresente um bom desempenho. Teste alguns valores para esse parâmetro até você conseguir um desempenho nos dados de teste semelhante ao obtido nos dados de treinamento e que seja superior ao obtido com a RNA base (sem regularização). A sua nota nesse item desse trabalho depende de você obter uma RNA sem problema de \"overfitting\" com um bom desempenho nos dados de teste.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: configuração da RNA com regularização L2\n",
    "\n",
    "# Reinicializa o gerador de números aleatórios\n",
    "np.random.seed(43)\n",
    "\n",
    "# Cria rede neural deep learning com regularizaçõa L2 e apresenta sua configuração\n",
    "#### COMECE AQUI ### (≈3 linhas)\n",
    "#lamb \n",
    "#rnaL2 \n",
    "#\n",
    "### TERMINE AQUI ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Model: \"sequential_1\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    dense_3 (Dense)              (None, 40)                120       \n",
    "    _________________________________________________________________\n",
    "    dense_4 (Dense)              (None, 6)                 246       \n",
    "    _________________________________________________________________\n",
    "    dense_5 (Dense)              (None, 1)                 7         \n",
    "    =================================================================\n",
    "    Total params: 373\n",
    "    Trainable params: 373\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #8: Compilação e treinamento da RNA com regularização L2\n",
    "\n",
    "Agora você vai treinar a sua RNA com regularização L2 usando o método de otimização do gradiente descentende com momento. Assim, na célula abaixo, compile e treine a sua RNA usando os mesmos parâmetros da RNA base, ou seja:\n",
    "\n",
    "- métrica: exatidão;\n",
    "- método do gradiente descendente com momento;\n",
    "- constante beta1 = 0,9;\n",
    "- decay = 0;\n",
    "- taxa de aprendizagem = 0,01;\n",
    "- nesterov = True\n",
    "- número de épocas = 30.000;\n",
    "- batch_size = 211. \n",
    "\n",
    "**Importante:** Escolha o parâmetro verbose=0 no método fit para evitar de imprimir os resultados das 30.000 épocas de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: compilação e treinamento da RNA com regularização L2 usando o método do gradiente descendente com momento\n",
    "\n",
    "# importa do keras a classe dos otimizadores\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Configuração do otomizador\n",
    "### COMECE AQUI ### (≈ 2 linhas)\n",
    "#mom \n",
    "#\n",
    "### TERMINE AQUI ###\n",
    "\n",
    "# Treinamento da RNA\n",
    "### COMECE AQUI ### (≈ 1 linha)\n",
    "#historyL2 \n",
    "### TERMINE AQUI ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos resultados\n",
    "\n",
    "Execute a célula a seguir para fazer os gráficos da função de custo e da métrica para os dados de treinamento e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva treinamento na variável history para visualização\n",
    "history_dictL2 = historyL2.history\n",
    "\n",
    "# Salva custos, métricas e epocas em vetores \n",
    "custoL2 = history_dictL2['loss']\n",
    "accL2 = history_dictL2['acc']\n",
    "val_custoL2 = history_dictL2['val_loss']\n",
    "val_accL2 = history_dictL2['val_acc']\n",
    "\n",
    "# Cria vetor de épocas\n",
    "epocasL2 = range(1, len(custoL2) + 1)\n",
    "\n",
    "# Gráfico dos valores de custo\n",
    "plt.plot(epocasL2, custoL2, 'bo', label='Custo - treinamento')\n",
    "plt.plot(epocasL2, val_custoL2, 'b', label='Custo - validação')\n",
    "plt.title('Valor da função de custo – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Custo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico dos valores da métrica\n",
    "plt.plot(epocasL2, accL2, 'bo', label='Exatidao- treinamento')\n",
    "plt.plot(epocasL2, val_accL2, 'b', label='Exatidao - validação')\n",
    "plt.title('Valor da métrica – treinamento e validação')\n",
    "plt.xlabel('Exatidao')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula a seguir para calcular o custo e a exatidão pra os dados de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método evaluate calcule o custo e a exatidão e depois apresenta os resultados\n",
    "custo_e_metricas_trainL2 = rnaL2.evaluate(X_train, Y_train)\n",
    "custo_e_metricas_valL2 = rnaL2.evaluate(X_val, Y_val)\n",
    "custo_e_metricas_testL2 = rnaL2.evaluate(X_test, Y_test)\n",
    "\n",
    "print(custo_e_metricas_trainL2)\n",
    "print(custo_e_metricas_valL2)\n",
    "print(custo_e_metricas_testL2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplo de saída esperada:**\n",
    "\n",
    "    [0.2463980802992509, 0.9478673]\n",
    "    [0.21228089451789856, 0.96]\n",
    "    [0.33273865342140196, 0.94]\n",
    "\n",
    "Execute a célula abaixo para visualizar a fronteira de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"RNA com regularização L2\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0.75,0.40])\n",
    "axes.set_ylim([-0.75,0.65])\n",
    "plot_decision_boundary(rnaL2, X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos resultados\n",
    "\n",
    "Pelos gráficos da função de custo e da métrica você deveria observar o seguinte:\n",
    "\n",
    "- O valor do custo para os dados de treinamento e de validação devem apresentar um comportamento semelhante, ou seja, ambos diminuem com o vanço do treinamento.\n",
    "- A exatidão obtida para os dados de treinamento, validação teste devem ser semelhantes.\n",
    "\n",
    "A fronteira de decisão deve estar mais suave e separando de forma mais precisa as duas classes. Podendo-se concluir que não deve estar mais ocorrendo problema de \"overfitting\" e a exatidão dos dados de teste deve apresentar um resultado melhor do que no caso da RNA base.\n",
    "\n",
    "**Observações:**\n",
    "\n",
    "- Lambda é um hiperpâmetro que deve ser ajustado usando os dados de validação.\n",
    "- Regularização torna a fronteira de decisão mais suave. Mas se lambda for muito grande a RNA pode apresentar problemas de \"underfitting\".\n",
    "\n",
    "**O que de fato a regularização está fazendo?**\n",
    "\n",
    "Regularização L2 se baseia na hipótese de que uma RNA com pesos pequenos é melhor do que um RNA com pesos grandes. Dessa forma, a penalização dos pesos, usando o seu valor ao quadrado na função de custo, faz com que todos os pesos se tornem menores, pois o custo de ter pesos grandes se torna muito alto. O resultado disso é a obtenção de uma RNA cujas saídas variam pouco em função de variações nas entradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Dropout\n",
    "\n",
    "Como visto, \"dropout\" é uma técnica de regularização aplicada a RNAs deep learning. No processo de \"dropout\" alguns neurônios são desligados em cada iteração. O vídeo a seguir apresenta o processo de \"dropout\" para uma RNA de 4 camadas.\n",
    "\n",
    "\n",
    "<center>\n",
    "<video width=\"620\" height=\"440\" src=\"dropout2_kiank.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "<caption><center> <u> Figura 3 </u>: Aplicação de \"dropout\" na primeira e terceira camadas escondidas. <br> $1^{st}$ camada: são desligados em média 40% dos neurônios.  $3^{rd}$ camada: são desligados em média 20% dos neurônios (Andre Ng, deeplearning.ai). </center></caption>\n",
    "\n",
    "Observe que quando deligamos alguns neurônios de fato modificamos a nossa RNA. A ideia do \"dropout\" é em cada iteração treinarmos uma RNA diferente que usa somente um subconjunto dos neurônios. Com isso, os neurônios ficam menos sensíveis a serem ativados por um único exemplo de treinamento em razão do fato de que esse mesmo neurônio pode ser desligado em outra iteração.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #9: Criação da RNA com \"dropout\"\n",
    "\n",
    "O \"dropout\" é implementado no Keras durante a criação da RNA. Então crie a função build_model_Dp, modificando a sua função build_model para incluir o \"dropout\". \n",
    "\n",
    "Utilize novamente a mesma configuração da RNA, ou seja, 2 camadas intermediárias e uma camada de saída com as seguintes características:\n",
    "\n",
    "- Primeira camada: número de neurônios n1, função de ativação ReLu, com dropout;\n",
    "- Segunda camada: número de neurônios n2, função de ativação ReLu, com dropout;\n",
    "- Camada de saída: número de neurônio n3, função de ativação sigmóide, sem dropout.\n",
    "\n",
    "Essa função deve receber como entrada a dimensão dos dados de entrada, os números de neurônios das 3 camadas e as frações dos neurônios que devem ser desligados na primeira camada (frac1) e na segunda camada (frac2). \n",
    "\n",
    "**Observação:** \n",
    "\n",
    "- Em razão do número de neurônios da segunda camada dessa RNA ser muito menor do que da primeira camada, pode-se usar frações de desligamento de neurônios diferentes para as duas camadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Função para criação da RNA com \"dropout\"\n",
    "\n",
    "# Importa classes do Keras de modelos e camadas\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "def build_model_Dp(data_shape, n1, n2, n3, frac1, frac2):\n",
    "    \"\"\"\n",
    "    Essa função configura uma rede neural deep-learnig\n",
    "    \n",
    "    Argumentos:\n",
    "    data_shape = tuple com dimensões dos dados de entrada da rede\n",
    "    n1 = número de neurônios da primeira camada\n",
    "    n2 = número de neurônios da segunda camada\n",
    "    n3 = número de neurônios da camada de saída\n",
    "    frac1 = fração de neurônios desligados na 1a camada\n",
    "    frac2 = fração de neurônios desligados na 2a camada\n",
    "       \n",
    "    Retorna: modelo da rede neural\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Adicione as camadas em seu modelo de RNA\n",
    "    #### COMECE AQUI ### (≈5 linhas)\n",
    "    #\n",
    "    ### TERMINE AQUI ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo configure a sua RNA usando os mesmos parâmetros da RNA base, ou seja, n1 = 40, n2 = 6, n3 = 1. Após criar a RNA utilize o método summary para visualizar a sua rede.\n",
    "\n",
    "**Importante: nesse exercício o seu objetivo é obter uma RNA que não realiza \"overfitting\" usando o método de \"dropout\". A escolha das  frações de neurônios desligados nas camadas (frac1 e frac2) é fundamental para que a RNA apresente um bom desempenho. Teste alguns valores para esses parâmetros até você conseguir um desempenho nos dados de teste semelhante ao obtido nos dados de treinamento e que seja superior ao obtido com a RNA base (sem regularização). A sua nota nesse item desse trabalho depende de você obter uma RNA sem problema de \"ovrefitting\" com um bom desempenho nos dados de teste.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: Função para configuração da RNA com \"dropout\"\n",
    "\n",
    "# Reinicializa o gerador de números aleatórios\n",
    "np.random.seed(43)\n",
    "\n",
    "# Cria rede neural deep learning com regularizaçõa L2 e apresenta sua configuração\n",
    "#### COMECE AQUI ### (≈ 4 linhas)\n",
    "#frac1 \n",
    "#frac2 \n",
    "#rnaDp \n",
    "#\n",
    "### TERMINE AQUI ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saída esperada:**\n",
    "\n",
    "    Model: \"sequential_2\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    dense_6 (Dense)              (None, 40)                120       \n",
    "    _________________________________________________________________\n",
    "    dropout (Dropout)            (None, 40)                0         \n",
    "    _________________________________________________________________\n",
    "    dense_7 (Dense)              (None, 6)                 246       \n",
    "    _________________________________________________________________\n",
    "    dropout_1 (Dropout)          (None, 6)                 0         \n",
    "    _________________________________________________________________\n",
    "    dense_8 (Dense)              (None, 1)                 7         \n",
    "    =================================================================\n",
    "    Total params: 373\n",
    "    Trainable params: 373\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício #10: Compilação e treinamento da RNA com \"dropout\"\n",
    "\n",
    "Agora você vai treinar a sua RNA com \"dropout\" usando novamente o método de otimização do gradiente descentende com momento. Assim, na célula abaixo, compile e treine a sua RNA usando os mesmos hiperparâmetros da RNA base, ou seja:\n",
    "\n",
    "- métrica: exatidão;\n",
    "- método do gradiente descendente com momento;\n",
    "- constante beta1 = 0,9;\n",
    "- decay = 0;\n",
    "- nesterov = True;\n",
    "- taxa de aprendizagem = 0,01;\n",
    "- número de épocas = 10.000;\n",
    "- batch_size = 211. \n",
    "\n",
    "**Importante:** Escolha o parâmetro verbose=0 no método fit para evitar de imprimir os resultados das 30.000 épocas de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA VOCÊ FAZER: compilação e treinamento da RNA com dropout usando o método do gradiente descendente com momento\n",
    "\n",
    "# importa do keras a classe dos otimizadores\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Configuração do otomizador\n",
    "### COMECE AQUI ### (≈ 2 linhas)\n",
    "#mom \n",
    "#\n",
    "### TERMINE AQUI ###\n",
    "\n",
    "# Treinamento da RNA\n",
    "### COMECE AQUI ### (≈ 1 linha)\n",
    "#historyDp\n",
    "### TERMINE AQUI ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos resultados\n",
    "\n",
    "Execute a célula a seguir para fazer os gráficos da função de custo e da métrica para os dados de treinamento e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva treinamento na variável history para visualização\n",
    "history_dictDp = historyDp.history\n",
    "\n",
    "# Salva custos, métricas e epocas em vetores \n",
    "custoDp = history_dictDp['loss']\n",
    "accDp = history_dictDp['acc']\n",
    "val_custoDp = history_dictDp['val_loss']\n",
    "val_accDp = history_dictDp['val_acc']\n",
    "\n",
    "# Cria vetor de épocas\n",
    "epocasDp = range(1, len(custoDp) + 1)\n",
    "\n",
    "# Gráfico dos valores de custo\n",
    "plt.plot(epocasDp, custoDp, 'bo', label='Custo - treinamento')\n",
    "plt.plot(epocasDp, val_custoDp, 'b', label='Custo - validação')\n",
    "plt.title('Valor da função de custo – treinamento e validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Custo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico dos valores da métrica\n",
    "plt.plot(epocasDp, accDp, 'bo', label='Exatidao- treinamento')\n",
    "plt.plot(epocasDp, val_accDp, 'b', label='Exatidao - validação')\n",
    "plt.title('Valor da métrica – treinamento e validação')\n",
    "plt.xlabel('Exatidao')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula a seguir para calcular o custo e a exatidão pra os dados de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método evaluate calcula o custo e a exatidão e depois apresenta os resultados\n",
    "custo_e_metricas_trainDp = rnaDp.evaluate(X_train, Y_train)\n",
    "custo_e_metricas_valDp = rnaDp.evaluate(X_val, Y_val)\n",
    "custo_e_metricas_testDp = rnaDp.evaluate(X_test, Y_test)\n",
    "\n",
    "print(custo_e_metricas_trainDp)\n",
    "print(custo_e_metricas_valDp)\n",
    "print(custo_e_metricas_testDp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplo de saída esperada:**\n",
    "\n",
    "    [0.20544989753108453, 0.93838865]\n",
    "    [0.26852761328220365, 0.96]\n",
    "    [0.3201810669898987, 0.93]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a célula abaixo para visualizar a fronteira de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('RNA com \"dropout\"')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0.75,0.40])\n",
    "axes.set_ylim([-0.75,0.65])\n",
    "plot_decision_boundary(rnaDp, X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise dos resultados\n",
    "\n",
    "Pelos gráficos da função de custo e da métrica você deve observar o seguinte:\n",
    "\n",
    "- O valor do custo para os dados de treinamento devem apresentar um comportamento oscilatório em razão do desligamento aleatório de neurônios em cada iteração do treinamento.\n",
    "- A exatidão obtida para os dados de treinamento, validação teste devem ser semelhantes.\n",
    "\n",
    "A fronteira de decisão deve estar muito mais suave, mostrando o poder do \"dropout\" de generalizar a solução. Pode-se concluir que não está mais ocorrendo problema de \"overfitting\" e a função de custo dos dados de teste deve apresentar um resultado melhor do que no caso da RNA base.\n",
    "\n",
    "**Observações:**\n",
    "\n",
    "- A fração de neurônios desligados por iteração (frac) é um hiperpâmetro que deve ser ajustado usando os dados de validação.\n",
    "- O \"dropout\" torna a fronteira de decisão mais suave. Mas se fração de neurônios desligados for muito grande a RNA pode apresentar problemas de \"underfitting\".\n",
    "\n",
    "**O que de fato o \"dropout\" está fazendo?**\n",
    "\n",
    "Uma explicação intuitiva da razão do “dropout” funcionar para diminuir “overfitting” é que ao zerar aleatoriamente as saídas de alguns neurônios das camadas durante o treinamento, é como se a RNA ficasse menor e uma RNA menor tem mais tendência de apresentar problemas de “underfitting” e menos de apresentar problemas de “overfitting”. Outra explicação seria o fato de que o treinamento com “dropout” é distribuído mais uniformemente entre todos os neurônios da RNA, evitando que grupos de neurônios se especializem em dados de treinamento específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Conclusão\n",
    "\n",
    "A conclusão que você deve obter desse trabalho é que regularização é muito eficiente para reduzir problemas de \"overfitting\" e, assim, obter uma RNA com um desempenho melhor para dados que não foram utilizados no treinamento da rede. Em muitos casos, principalmente quando se tem um número pequeno de exemplos de treinamento, regulariação é fundamental para se obter RNAs com bom desempenho.\n",
    "\n",
    "Observe que regularização piora o desempenho nos dados de treinamento. Isso ocorre porque a regularização limita a habilidade da rede realizar \"overfitting\" nos dados de treinamento. Mas na medida em que no final obtém-se um melhor desempenho nos dados de teste o resultado final é melhor.\n",
    "\n",
    "**O que deve ser lembrado desse trabalho:**\n",
    "- Regularização ajuda a reduzir \"overfitting\";\n",
    "- Regularização resulta em pesos de valores menores;\n",
    "- Regularização L2 e \"dropout\" são técnicas eficientes de regularização.\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "SXQaI",
   "launcher_item_id": "UAwhh"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
