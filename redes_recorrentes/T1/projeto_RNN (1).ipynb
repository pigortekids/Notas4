{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projeto_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTxEu_HsyZbm",
        "colab_type": "text"
      },
      "source": [
        "#Predição do Bitcoin com RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4NHl-wVx_FM",
        "colab_type": "text"
      },
      "source": [
        "###Esse projeto tem como objetivo construir um modelo que prevê os valores futuros de Bitcoin do dataset abaixo:\n",
        "https://www.kaggle.com/mczielinski/bitcoin-historical-data\n",
        "\n",
        "###Esse dataset contêm os valores de transações de Bitcoin de minuto a minuto desde 01/01/2012 até 22/04/2020, com as seguintes colunas:\n",
        "- Timestamp (começo da janela de tempo de um minuto em horário Unix)\n",
        "- Open (preço inicial)\n",
        "- High (maior preço)\n",
        "- Low (menor preço)\n",
        "- Close (preço final)\n",
        "- Volume_(BTC) (quantidade de Bitcoin transacionado)\n",
        "- Volume_(Currency) (quantidade de moeda transacionado)\n",
        "- Weighted_Price (preço médio)\n",
        "\n",
        "Usaremos a variavel Timestamp para sequênciar os valores e tentaremos predizer a variável Weighted_Price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh_yB74BwzOm",
        "colab_type": "code",
        "outputId": "e8f1a3c0-eb36-4d65-bff6-9a707c9d076e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "caminho_drive = '/content/drive/My Drive/colab/RNN/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYp7JpnA5AxR",
        "colab_type": "text"
      },
      "source": [
        "Primeiro vamos importar as bibliotecas que usaremos durante todo o notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc91TSX-5EzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timezone\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpbRhVmWyi4C",
        "colab_type": "text"
      },
      "source": [
        "Agora importamos o arquivo para começar a análise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T83UMe_lxASi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nm_arquivo = 'bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv'\n",
        "arquivo = pd.read_csv( caminho_drive + nm_arquivo )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uwJTMqXxaVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arquivo.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqHca5tky_IE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arquivo.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBG6tFUHvVNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_plot = pd.to_datetime(arquivo['Timestamp'], unit='s')\n",
        "\n",
        "plt.figure( figsize=(20, 8) )\n",
        "plt.plot( x_plot, arquivo['Weighted_Price'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3HcBcYjvq7D",
        "colab_type": "text"
      },
      "source": [
        "Primeira coisa que podemos perceber é que antes de 2017 temos muitos valores NaN, que significa que não tinhamos muitas transações da moeda. Vamos então filtrar esses dados com intuito de trabalharmos com os dados mais voláteis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeTjWTMhwI_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt = datetime(2019, 1, 1)\n",
        "timestamp = dt.replace(tzinfo=timezone.utc).timestamp()\n",
        "\n",
        "arquivo_maior_2017 = arquivo[ arquivo['Timestamp'] >= timestamp ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaTXUSoTwyvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_plot = pd.to_datetime(arquivo_maior_2017['Timestamp'], unit='s')\n",
        "\n",
        "plt.figure( figsize=(20, 8) )\n",
        "plt.plot( x_plot, arquivo_maior_2017['Weighted_Price'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJc9U5-4xHBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arquivo_maior_2017.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLE0AjH2y2N0",
        "colab_type": "text"
      },
      "source": [
        "Mesmo tirando o ano de 2017, ainda temos muitos casos NaN. Uma linha de Nan significa que não teve nenhuma transação na janela de tempo indicada, ou seja, o valor continuou igual, logo, uma ideia para preencher os valores vazios é de preencher todos os valores com o Close da última linha.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_GIa8i14SI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arquivo_maior_2017.sort_values( by=['Timestamp'] ) #garantido a seqência dos valores\n",
        "arquivo_na = arquivo_maior_2017.copy()\n",
        "\n",
        "for i in range( arquivo_maior_2017.shape[0] ):\n",
        "    if (i % 100000 == 0):\n",
        "        print( '{}/{} dados processados'.format( i, arquivo_maior_2017.shape[0] ) )\n",
        "    if pd.isna( arquivo_maior_2017.iloc[i][1] ):\n",
        "        valor_close = arquivo_na.iloc[i - 1][4]\n",
        "        arquivo_na.iloc[i] = [ arquivo_na.iloc[i][0] , valor_close , valor_close , valor_close , valor_close , 0 , 0 , valor_close ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_8ThuHF-qLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arquivo_na.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjcbONkE_VK8",
        "colab_type": "text"
      },
      "source": [
        "Olhando a página do dataset o autor diz que podem ter timestamps que não existem, que no momento da janela de tempo, a API que captura os arquivos não estava funcionando. Vamos ver se é muito grande essa quantidade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN6hTLq1_pP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valor_minimo = arquivo_na['Timestamp'].min()\n",
        "valor_maximo = arquivo_na['Timestamp'].max()\n",
        "\n",
        "quantidade_desejada = int( ( valor_maximo - valor_minimo ) / 60 ) + 1\n",
        "quantidade_real = arquivo_na.shape[0]\n",
        "\n",
        "diferenca = quantidade_desejada - quantidade_real\n",
        "diference_percentual = (diferenca / quantidade_desejada) * 100\n",
        "\n",
        "print('São {0} linhas não existentes em {1} linhas'.format(diferenca, quantidade_desejada))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXbHn1crpblD",
        "colab_type": "text"
      },
      "source": [
        "Como podemos ver, depois de 2017 não temos casos que a API não estava funcionando, então não precisamos nos preocupar.\n",
        "\n",
        "Vamos agora decidir nossas variaveis da RNN.\n",
        "\n",
        "Como ainda temos muito dados, podemos usar um numero de time steps grande (tomando cuidado para não deixar grande demais a ponto de estourar a RAM do Colab) e vamos utilizar todos os dados do arquivo, com objetivo de tentar uma boa predição.\n",
        "\n",
        "As transações de Bitcoin são feitas com uma demora de em média 10 minutos, com isso, devemos tentar predizer valores com pelo menos 10 minutos a frente, ou seja, o nosso future_steps deve ser >= 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY1ehXWqpY8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_steps = 60\n",
        "nr_features = arquivo_na.shape[1] - 1 #tiramos a variável de tempo\n",
        "future_steps = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvPzH-_0tlwG",
        "colab_type": "text"
      },
      "source": [
        "Agora podemos preparar os dados que vão entrar no modelo.\n",
        "\n",
        "Primeiro vamos normalizar os dados, deixando todos eles com valores entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qla1jD8X2-jW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "arquivo_np = arquivo_na[  arquivo_na.columns[1:] ].to_numpy() #pega todas as colunas, menos a de data, e transforma em uma array\n",
        "\n",
        "dados_norm = scaler.fit_transform( arquivo_np )\n",
        "\n",
        "dados_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD96AiaU3dzs",
        "colab_type": "text"
      },
      "source": [
        "Agora vamos coloca-los no formato certo para entrar no modelo, onde cada exemplo de X terá (time_steps) linhas e (nr_features) colunas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0_l58cH3ltm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qnt_total = len(dados_norm)\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in range (time_steps, qnt_total - future_steps):\n",
        "    X.append(dados_norm[i - time_steps : i])\n",
        "    Y.append(dados_norm[i : i + future_steps , -1])\n",
        "\n",
        "X_array = np.array( X )\n",
        "Y_array = np.array( Y )\n",
        "\n",
        "print('Dimensão de X = {}'.format( X_array.shape ))\n",
        "print('Dimensão de Y = {}'.format( Y_array.shape ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFJQIKPl4Bqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABkgn4XV4Gx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kOgUu0-1GNk",
        "colab_type": "text"
      },
      "source": [
        "Agora vamos dividir os dados em treino, validação e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJUQKanizTdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "porc_treino = 0.7\n",
        "porc_validacao = 0.15\n",
        "porc_teste = 0.15\n",
        "\n",
        "qnt_treino = int( qnt_total * porc_treino )\n",
        "qnt_validacao = int( qnt_total * porc_validacao )\n",
        "qnt_teste = int( qnt_total * porc_teste )\n",
        "\n",
        "X_treino = X_array[ : qnt_treino ]\n",
        "X_validacao = X_array[ qnt_treino : qnt_treino + qnt_validacao ]\n",
        "X_teste = X_array[ qnt_treino + qnt_validacao : ]\n",
        "\n",
        "Y_treino = Y_array[ : qnt_treino ]\n",
        "Y_validacao = Y_array[ qnt_treino : qnt_treino + qnt_validacao ]\n",
        "Y_teste = Y_array[ qnt_treino + qnt_validacao : ]\n",
        "\n",
        "print('{} dados no total'.format( qnt_total ))\n",
        "print('{} dados para o treino'.format( X_treino.shape[0] ))\n",
        "print('{} dados para a validação'.format( X_validacao.shape[0] ))\n",
        "print('{} dados para o teste'.format( X_teste.shape[0] ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJPaG0vy50fZ",
        "colab_type": "text"
      },
      "source": [
        "Podemos agora ir para o nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex7uMbp3Bpme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add( LSTM(units=30, input_shape=(time_steps, nr_features)) )\n",
        "#model.add( LSTM(units=30, input_shape=(time_steps, nr_features), return_sequences=True) )\n",
        "\n",
        "#model.add( LSTM(units=20, return_sequences=True) )\n",
        "\n",
        "#model.add( LSTM(units=10) )\n",
        "\n",
        "model.add( Dense(units=future_steps) )\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy','mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGiolV_66l37",
        "colab_type": "text"
      },
      "source": [
        "Com os dados preparados e o modelo criado, podemos agora começar o treino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bZatZhR6kYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "historico = model.fit(X_treino, Y_treino, epochs=100, batch_size=time_steps, validation_data=(X_validacao, Y_validacao), shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g8d2w1M9KWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(historico.history['loss'], label='Training')\n",
        "plt.plot(historico.history['val_loss'], label='Validation')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}